# ğŸª™ Gold Recovery Prediction â€” Flotation Plant
PredicciÃ³n de la recuperaciÃ³n de oro en etapas crÃ­ticas del proceso.
<p align="center"> <img src="https://img.shields.io/badge/Status-Completed-brightgreen" /> <img src="https://img.shields.io/badge/Jupyter-Notebook-orange" /> <img src="https://img.shields.io/badge/Python-3.10-blue" /> <img src="https://img.shields.io/badge/Metric-sMAPE-purple" /> <img src="https://img.shields.io/badge/Model-RandomForestRegressor-green" /> </p>

### ğŸ“‘ Tabla de Contenidos

- ğŸ“Œ DescripciÃ³n del Proyecto
- ğŸ¯ Objetivo
- ğŸ“‚ Datos
- ğŸ§  Enfoque de la SoluciÃ³n
- ğŸ› ï¸ TecnologÃ­as Utilizadas
- ğŸ“Š AnÃ¡lisis y Hallazgos Clave
- ğŸ¤– Modelado y MÃ©trica sMAPE
- ğŸ§¾ Conclusiones


## ğŸ“Œ DescripciÃ³n del Proyecto

Este proyecto se centra en una planta de procesamiento de oro que utiliza flotaciÃ³n y varias etapas de limpieza (cleaning stages) para enriquecer el mineral. La meta es construir un modelo capaz de predecir la recuperaciÃ³n de oro en etapas crÃ­ticas del proceso:

- rougher.output.recovery
- final.output.recovery

La evaluaciÃ³n se realiza con la mÃ©trica symmetric Mean Absolute Percentage Error (sMAPE), definida asÃ­:

<p align="center">
$sMAPE = \frac{1}{N}\sum_{i=1}^N \frac{|y_i - \hat{y}_i|}{(|y_i| + |\hat{y}_i|)/2} \times 100\%$
</p>
El resultado final combina ambas etapas:

<p align="center"> $
sMAPE_{final} = 0.25 \cdot sMAPE_{rougher} + 0.75 \cdot sMAPE_{final}
$ </p>


## ğŸ¯ Objetivo

Desarrollar un modelo de machine learning que:

âœ”ï¸ prediga correctamente la recuperaciÃ³n rougher y final

âœ”ï¸ minimice el sMAPE combinado, requerido por negocio

âœ”ï¸ sea robusto ante diferencias entre train y test

âœ”ï¸ utilice solo caracterÃ­sticas disponibles en el entorno real (dataset test)

## ğŸ“‚ Datos

El proyecto utiliza tres archivos:

- gold_recovery_train.csv â†’ dataset de entrenamiento
- gold_recovery_test.csv â†’ dataset de prueba (sin objetivos)
- gold_recovery_full.csv â†’ dataset maestro con todos los datos

CaracterÃ­sticas principales:

- Ãndice temporal (date)
- Variables fÃ­sico-quÃ­micas del proceso
- Caudales, reactivos, concentraciones metÃ¡licas (Au, Ag, Pb)
- Salidas de los procesos rougher y cleaner

## ğŸ§  Enfoque de la SoluciÃ³n
### 1ï¸âƒ£ PreparaciÃ³n de Datos

ğŸ” ExploraciÃ³n inicial

- RevisiÃ³n de tipos de datos, valores nulos y estructura temporal.
- IdentificaciÃ³n de columnas presentes en train pero ausentes en test (principalmente columnas objetivo y valores tardÃ­os).

ğŸ§ª ValidaciÃ³n de la fÃ³rmula de recuperaciÃ³n

- Se recalculÃ³ rougher.output.recovery.
- Se comparÃ³ contra la columna original â†’ MAE â‰ˆ 7.88eâ€“15, confirmando consistencia.

ğŸ§¹ Limpieza

- EliminaciÃ³n de filas sin informaciÃ³n de aÃ±o o con anomalÃ­as fÃ­sicas.
- ConversiÃ³n date â†’ datetime.
- AlineaciÃ³n completa entre train, test y full.

### 2ï¸âƒ£ AnÃ¡lisis Exploratorio (EDA)

ğŸ“ˆ ConcentraciÃ³n de metales (Au, Ag, Pb)

- Au aumenta de manera consistente a travÃ©s de rougher â†’ cleaner â†’ final.
- Ag aumenta pero luego disminuye en etapas profundas (mÃ¡s selectividad hacia Au).
- Pb se comporta de manera estable, con incrementos leves.

ğŸ“Š DistribuciÃ³n del tamaÃ±o de partÃ­cula

- Se compararon train vs test.
- La prueba KS mostrÃ³ diferencias estadÃ­sticamente significativas.
- Esto afecta la estabilidad del modelo â†’ se optÃ³ por usar modelos robustos (RF).

âš ï¸ IdentificaciÃ³n de anomalÃ­as

- Se sumÃ³ la concentraciÃ³n total de metales por etapa.
- Se detectaron valores cercanos a 0 o fÃ­sicamente imposibles.
- Se eliminaron filas con totales < 1 para asegurar integridad del dataset.

## ğŸ¤– Modelado y MÃ©trica sMAPE
### 1ï¸âƒ£ CreaciÃ³n de la FunciÃ³n sMAPE

Se implementÃ³ funciÃ³n personalizada para:

- sMAPE_rougher
- sMAPE_final
- sMAPE_total (25% rougher + 75% final)

Se integrÃ³ como scorer para GridSearchCV y cross_val_score.

### 2ï¸âƒ£ Entrenamiento y SelecciÃ³n de Modelos

Modelos probados:

| Modelo                    | Ventajas                | Resultado               |
| ------------------------- | ----------------------- | ----------------------- |
| **LinearRegression**      | simple, interpretable   | desempeÃ±o medio         |
| **DecisionTreeRegressor** | captura no-linealidades | tendencia a sobreajuste |
| **RandomForestRegressor** | robusto, estable        | **mejor desempeÃ±o**     |


DespuÃ©s de probar modelos con CV (cv=5), el mejor fue:

<p align="center"> <b>â­ RandomForestRegressor </b></p>

Luego se realizÃ³ Grid Search:

<p align="center">
n_estimators = [10, 15, 20, 25, 30]
  
max_depth = [3, 4, 5, 6, 7]
</p>

#### âœ”ï¸ Mejor modelo final:

<p align="center">
  RandomForestRegressor(  
    random_state=12345,    
    n_estimators=30,    
    max_depth=4
    )

</p>

### 3ï¸âƒ£ Resultados Finales

El modelo final fue entrenado de forma independiente para:

- rougher.output.recovery
- final.output.recovery

El desempeÃ±o sobre el conjunto de prueba fue:

<p align="center"><b> ğŸ¥‡ sMAPE total â‰ˆ 7.52% </b><p align="center">  </p>

Un valor excelente para un proceso industrial complejo con alto ruido en sensÃ³rica.

ğŸ§¾ Conclusiones

- Se construyÃ³ un pipeline sÃ³lido para preparaciÃ³n, anÃ¡lisis y modelado.
- Se detectaron y eliminaron anomalÃ­as fÃ­sicas que afectaban la estabilidad del modelo.
- El modelo RandomForestRegressor fue el mÃ¡s robusto frente a diferencias entre train y test.
- El sMAPE obtenido (â‰ˆ7.5%) demuestra la capacidad predictiva del modelo en un entorno real.
- El proceso revela la importancia de:
  - selecciÃ³n correcta de variables
  - alineaciÃ³n entre train/test
  - mÃ©tricas personalizadas
  - validaciÃ³n cruzada
